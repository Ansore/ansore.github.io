<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>CNN基于Tensorflow实现cifar10数据集80准确率 | Ansore</title><meta name="keywords" content="cnn,tensorflow,cifar"><meta name="author" content="Ansore"><meta name="copyright" content="Ansore"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="数据导入和预处理本文使用的是CIFAR10的数据集。CIFAR10包含了十个类型的图片，有60000张大小为32x32的彩色图片，其中50000张用于训练，10000张用于测试。数据集共分为5个训练块和1个测试块，每个块有10000个图像，包含以下数据：  data——1个数据块中包含1个10000*3072大小的uint8s数组，数组每行存储1张32x32图像，第一个1024数组包含红色通道，下">
<meta property="og:type" content="article">
<meta property="og:title" content="CNN基于Tensorflow实现cifar10数据集80准确率">
<meta property="og:url" content="https://blog.ansore.top/posts/4c3e71da.html">
<meta property="og:site_name" content="Ansore">
<meta property="og:description" content="数据导入和预处理本文使用的是CIFAR10的数据集。CIFAR10包含了十个类型的图片，有60000张大小为32x32的彩色图片，其中50000张用于训练，10000张用于测试。数据集共分为5个训练块和1个测试块，每个块有10000个图像，包含以下数据：  data——1个数据块中包含1个10000*3072大小的uint8s数组，数组每行存储1张32x32图像，第一个1024数组包含红色通道，下">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://img.ansore.de/2022/04/28/626969f586f24.jpg">
<meta property="article:published_time" content="2018-03-29T08:23:32.000Z">
<meta property="article:modified_time" content="2024-01-03T14:54:50.112Z">
<meta property="article:author" content="Ansore">
<meta property="article:tag" content="cnn">
<meta property="article:tag" content="tensorflow">
<meta property="article:tag" content="cifar">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://img.ansore.de/2022/04/28/626969f586f24.jpg"><link rel="shortcut icon" href="/images/favicon.ico"><link rel="canonical" href="https://blog.ansore.top/posts/4c3e71da"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//www.clarity.ms"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.css" media="print" onload="this.media='all'"><script>(function(c,l,a,r,i,t,y){
    c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
    t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
    y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
})(window, document, "clarity", "script", "bmljz8fd92");</script><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#1f1f1f","position":"bottom-left"},
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: true,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'CNN基于Tensorflow实现cifar10数据集80准确率',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-01-03 22:54:50'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-5371728450390652" crossorigin="anonymous"></script><meta name="generator" content="Hexo 6.0.0"><link rel="alternate" href="/atom.xml" title="Ansore" type="application/atom+xml">
</head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/images/logo.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data is-center"><div class="data-item"><a href="/archives/"><div class="headline">文章</div><div class="length-num">176</div></a></div><div class="data-item"><a href="/tags/"><div class="headline">标签</div><div class="length-num">52</div></a></div><div class="data-item"><a href="/categories/"><div class="headline">分类</div><div class="length-num">21</div></a></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-th"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-user"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://img.ansore.de/2022/04/28/626969f586f24.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Ansore</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-th"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-user"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">CNN基于Tensorflow实现cifar10数据集80准确率</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2018-03-29T08:23:32.000Z" title="发表于 2018-03-29 16:23:32">2018-03-29</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-01-03T14:54:50.112Z" title="更新于 2024-01-03 22:54:50">2024-01-03</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">6.9k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>23分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="CNN基于Tensorflow实现cifar10数据集80准确率"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h2 id="数据导入和预处理"><a href="#数据导入和预处理" class="headerlink" title="数据导入和预处理"></a>数据导入和预处理</h2><p>本文使用的是CIFAR10的数据集。CIFAR10包含了十个类型的图片，有60000张大小为32x32的彩色图片，其中50000张用于训练，10000张用于测试。数据集共分为5个训练块和1个测试块，每个块有10000个图像，包含以下数据：</p>
<ol>
<li>data——1个数据块中包含1个10000*3072大小的uint8s数组，数组每行存储1张32x32图像，第一个1024数组包含红色通道，下一个1024数组包含绿色通道，最后一个1024包含蓝色通道。图像存储以行顺序为主，所以数组的前32列为图像的第一行红色通道的值。</li>
<li>lables——1个数据块包含1个10000数的列表，范围为0-9，分别对应图片不同的分类，索引值i的数值表示数组data中的第i个图片的标签。</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">load_CIFAR_batch</span>(<span class="params">filename</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot; 载入cifar数据集的一个batch &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(filename, <span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        datadict = p.load(f, encoding=<span class="string">&#x27;latin1&#x27;</span>)</span><br><span class="line">        X = datadict[<span class="string">&#x27;data&#x27;</span>]</span><br><span class="line">        Y = datadict[<span class="string">&#x27;labels&#x27;</span>]</span><br><span class="line">        X = X.reshape(<span class="number">10000</span>, <span class="number">3</span>, <span class="number">32</span>, <span class="number">32</span>).transpose(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>).astype(<span class="string">&quot;float32&quot;</span>)</span><br><span class="line">        Y = np.array(Y)</span><br><span class="line">        <span class="keyword">return</span> X, Y</span><br><span class="line"></span><br><span class="line"><span class="comment"># one hot 处理</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">make_one_hot</span>(<span class="params">data1</span>):</span><br><span class="line">    <span class="keyword">return</span> (np.arange(<span class="number">10</span>)==data1[:,<span class="literal">None</span>]).astype(np.integer)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">load_CIFAR10</span>(<span class="params">ROOT</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot; 载入cifar全部数据 &quot;&quot;&quot;</span></span><br><span class="line">    xs = []</span><br><span class="line">    ys = []</span><br><span class="line">    <span class="keyword">for</span> b <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">6</span>):</span><br><span class="line">        f = os.path.join(ROOT, <span class="string">&#x27;data_batch_%d&#x27;</span> % (b,))</span><br><span class="line">        X, Y = load_CIFAR_batch(f)</span><br><span class="line">        xs.append(X)</span><br><span class="line">        ys.append(Y)</span><br><span class="line">    Xtr = np.concatenate(xs)</span><br><span class="line">    Ytr = np.concatenate(ys)</span><br><span class="line">    <span class="keyword">del</span> X, Y</span><br><span class="line">    Xte, Yte = load_CIFAR_batch(os.path.join(ROOT, <span class="string">&#x27;test_batch&#x27;</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># one hot 处理</span></span><br><span class="line">    Ytr = make_one_hot(Ytr)</span><br><span class="line">    Yte = make_one_hot(Yte)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> Xtr, Ytr, Xte, Yte</span><br></pre></td></tr></table></figure>

<p>读取过程中，将每张图片维度转换为[32,32,3]，然后将数据类型改变为float，每批数据都是10000x32x32x3，相当于超过了3000万个浮点数，数据类型float实际与float64相同，也就是说每个数字占用8个字节，这就意味着每批数据至少占用240M内存，一次将训练集和测试集载入内存的话，至少需要1.4G内存空间，这还只是数据的准备阶段。</p>
<p>函数load_CIFAR10函数传入的值为cifar10数据的加载的相对目录，读出数据后还要对10类标签进行one-hot编码，以供后来的softmax分类处理。该函数返回值分别为训练集图像、训练集标签、测试集图像、测试集标签，他们的索引值一一对应。</p>
<h2 id="创建模型"><a href="#创建模型" class="headerlink" title="创建模型"></a>创建模型</h2><p>TensorFlow基于数据流图的框架，首先定义模型之前要将各个节点表示成某种抽象的计算，边表示节点之间张量的联系。也就是说Tensorflow不单独地运行单一的复杂计算，而是先用图描述一系列可交互性的计算操作，然后全部一起在Python之外运行，提高运算效率。</p>
<p>本文采用的卷积神经网络（CNN）主要用来识别以为、缩放以及其他形式扭曲不变性的二维图像，相较于一般神经网络，卷积网络的输入图像和网络的拓扑结构能很好的吻合，特征提取和模式分类可以同时进行，并且都在训练中产生。采用监督学习训练模型，每一个输入对象都有一个期望的输出值，利用一组已知类别的样本调整分类器参数，使其各层参数最终分别收敛。</p>
<p>本文创建的模型，是一个多层架构，采用类似vgg16的结构创建模型，由卷积层和非线性层（nonlinearities）交替多次后排列构成，但是没有用到vgg16庞大的全连接层结构，设计思路如下：</p>
<ol>
<li>所有卷积层均使用3X3的小卷积核</li>
<li>两层卷积搭配一层池化</li>
<li>使用vgg16前三个卷积和池化操作，以2的次幂依次递增卷积核数量(64,128,256) </li>
<li>调整精度控制，防止过拟合或者欠拟合的情况</li>
<li>模型的全连接层没有采用vgg16的三层结构，卷积层输出后直接跟10分类的softmax classifier</li>
<li>初始化权重和偏置全部采用随机，防止0梯度的情况</li>
<li>建立状态可视化，分别记录训练过程中的损失以及对训练集准确率的变化</li>
<li>定义输入和输出节点，供安卓端调用</li>
</ol>
<h3 id="定义占位符"><a href="#定义占位符" class="headerlink" title="定义占位符"></a>定义占位符</h3><p>因为Tensorflow是基于图来计算的，每执行一步程序，都是一个op，整个程序在运行之前必须定义要执行的操作，placeholder其实也是一种常量，但是是由用户在调用run方法的时候传递的。在训练过程中，由于数据量比较庞大，不可能将所有数据一次性载入内存执行运算，所以运用placeholder在运算的时候传入一小部分数据进行运算，计算完毕以后再传入另外一部分进行运算，这样一直迭代下去，减少对计算机配置的需求。</p>
<p>首先创建图的输入部分，分别为inputnode（图片）和classes（分类），在定义这Tensor Variable时，需要指定名字，以方便安卓端调用的时候能找到计算流图中的输入位置（通过形参name指定），在Tensorflow进行运算的时候使用：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">&quot;inputs&quot;</span>):</span><br><span class="line">        x = tf.placeholder(tf.float32, [<span class="literal">None</span>, <span class="number">32</span>, <span class="number">32</span>, <span class="number">3</span>], name=<span class="string">&quot;inputnode&quot;</span>)</span><br><span class="line">        y_ = tf.placeholder(tf.float32, [<span class="literal">None</span>, <span class="number">10</span>], name=<span class="string">&quot;classes&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>图片输入x为浮点数4维张量，定义它的shape为[None, 32, 32, 3]，其中None可以为任意值，第2、3维是图片的尺寸，表示输入图片的大小为32x32像素，第4维为图片的颜色通道，黑白图片为1，彩色图片为3（r、g、b三个输入通道）。输入值y_是一个2维张量，每一行的10维向量代表不同图片的分类，这里输入的是图片标签的真实分类。</p>
<h3 id="权重和偏置初始化"><a href="#权重和偏置初始化" class="headerlink" title="权重和偏置初始化"></a>权重和偏置初始化</h3><p>当训练模型时，用变量来存储和更新参数。变量包含张量（Tensor）存放在内存中，建立模型时它们需要明确被初始化，训练模型后它们可以存放到磁盘。之后训练模型和分析可以直接加载。</p>
<p>创建模型的时候，变量初始化时加入轻微噪声，打破对称性，防止0梯度问题。为了避免在建模型的时候反复进行初始化操作，直接定义两个函数用于初始化权重和偏置：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">weight_variable</span>(<span class="params">shape</span>):</span><br><span class="line">    init = tf.random_normal(shape, stddev=<span class="number">0.01</span>)</span><br><span class="line">    <span class="keyword">return</span> tf.Variable(init, name=<span class="string">&quot;Weights&quot;</span>)</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">bias_variable</span>(<span class="params">shape</span>):</span><br><span class="line">    init = tf.random_normal(shape)</span><br><span class="line">    <span class="keyword">return</span> tf.Variable(init, name=<span class="string">&quot;biases&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>在tensorflow中创建一个变量的时候，需要将一个张量作为初始值传入构造函数Variable()。所有这些操作都需要指定张量的shape，也就是张量的维度。变量的维度通常是固定的。</p>
<h3 id="卷积、池化和dropout"><a href="#卷积、池化和dropout" class="headerlink" title="卷积、池化和dropout"></a>卷积、池化和dropout</h3><p>卷积运算可以理解成一种加权求和，通过卷积运算，可以使原信号特征增强，而且可以降低噪声，本文使用1步长、0边距的模板，保证输入和输出的向量是同样大小。</p>
<p>采用池化层的原因是，根据图像的局部相关性原理，对图像进行子采样可以减少计算量，同时也可以保证图像不变性，本文采用2x2大小的模板做最大池化。</p>
<p>Dropout在深度学习中，按照一定的概率使一部分神经元不被激活，也就是说按一定概率将它从神经网络中暂时丢弃，从而防止过度拟合。依然定义函数进行操作：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">conv2d</span>(<span class="params">x, W</span>):</span><br><span class="line">    conv = tf.nn.conv2d(x, W, strides=[<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>], padding=<span class="string">&#x27;SAME&#x27;</span>, name=<span class="string">&quot;Conv2D&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> conv</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">max_pool_2x2</span>(<span class="params">x</span>):</span><br><span class="line">    pool = tf.nn.max_pool(x, ksize=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>], strides=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>], padding=<span class="string">&#x27;SAME&#x27;</span>, name=<span class="string">&quot;MaxPool2D&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> pool</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">dropout</span>(<span class="params">x, keep</span>):</span><br><span class="line">    <span class="keyword">return</span> tf.nn.dropout(x, keep, name=<span class="string">&quot;dropout&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>每一层卷积之后，紧接着¬用一个非线性层，主要目的是在系统中引入非线性特征。本文中使用Relu层，具有比tanh和sigmoid函数更好的效率和速度，Relu层只要对input的所有值应用函数f(x)&#x3D;max(0,x)，也就是说这一层所有的negative activation为0，可以很大程度上减少存储空间，同时也可以加快收敛速度。添加卷积层同样抽象成一个函数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#　添加卷积层　</span></span><br><span class="line"><span class="comment"># inputs 输入数据　</span></span><br><span class="line"><span class="comment"># weight_shape权重格式　</span></span><br><span class="line"><span class="comment"># bias_shape 偏置格式</span></span><br><span class="line"><span class="comment"># keep_prob 过拟合</span></span><br><span class="line"><span class="comment"># activation_function激励函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">add_conv</span>(<span class="params">inputs, weight_shape, bias_shape, keep_prob, activation_function = <span class="literal">None</span></span>):</span><br><span class="line">    Weights1 = weight_variable(weight_shape)</span><br><span class="line">    biases1 = bias_variable(bias_shape)</span><br><span class="line">    <span class="comment"># 卷积</span></span><br><span class="line">    <span class="keyword">if</span> activation_function <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        conv = conv2d(inputs, Weights1) + biases1</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        conv = activation_function(conv2d(inputs, Weights1)+biases1)</span><br><span class="line">    drop = dropout(conv, keep_prob)</span><br><span class="line">    <span class="keyword">return</span> drop</span><br></pre></td></tr></table></figure>

<h3 id="定义网络结构"><a href="#定义网络结构" class="headerlink" title="定义网络结构"></a>定义网络结构</h3><p>本文采用卷积层和采样层（池化层）交替设置，即layer1的具体结构就是两层卷积层搭配一层采样层，layer2和layer3同样也是两层卷积层加上一层采样层，经过这样三层运算后图片维度变化为：</p>
<blockquote>
<p>input:32x32 -&gt; layer1:16x16 -&gt; layer2:8x8 -&gt; layer3:4x4</p>
</blockquote>
<p>网络结构代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># layer 1</span></span><br><span class="line">    <span class="keyword">with</span> tf.name_scope(<span class="string">&quot;layer1&quot;</span>):</span><br><span class="line">        drop1 = add_conv(images, [<span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">64</span>], [<span class="number">64</span>], <span class="number">1</span>, tf.nn.relu)</span><br><span class="line">        drop1 = add_conv(drop1, [<span class="number">3</span>, <span class="number">3</span>, <span class="number">64</span>, <span class="number">64</span>], [<span class="number">64</span>], <span class="number">1</span>, tf.nn.relu)</span><br><span class="line">        drop1 = max_pool_2x2(drop1)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># layer 2</span></span><br><span class="line">    <span class="keyword">with</span> tf.name_scope(<span class="string">&quot;layer2&quot;</span>):</span><br><span class="line">        drop2 = add_conv(drop1, [<span class="number">3</span>, <span class="number">3</span>, <span class="number">64</span>, <span class="number">128</span>], [<span class="number">128</span>], <span class="number">1</span>, tf.nn.relu)</span><br><span class="line">        drop2 = add_conv(drop2, [<span class="number">3</span>, <span class="number">3</span>, <span class="number">128</span>, <span class="number">128</span>], [<span class="number">128</span>], <span class="number">1</span>, tf.nn.relu)</span><br><span class="line">        drop2 = max_pool_2x2(drop2)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># layer 3</span></span><br><span class="line">    <span class="keyword">with</span> tf.name_scope(<span class="string">&quot;layer3&quot;</span>):</span><br><span class="line">        drop3 = add_conv(drop2, [<span class="number">3</span>, <span class="number">3</span>, <span class="number">128</span>, <span class="number">256</span>], [<span class="number">256</span>], <span class="number">1</span>, tf.nn.relu)</span><br><span class="line">        drop3 = add_conv(drop3, [<span class="number">3</span>, <span class="number">3</span>, <span class="number">256</span>, <span class="number">256</span>], [<span class="number">256</span>], <span class="number">1</span>, tf.nn.relu)</span><br><span class="line">        drop3 = max_pool_2x2(drop3)</span><br><span class="line">        </span><br><span class="line">    drop3_flat = tf.reshape(drop3, [-<span class="number">1</span>, <span class="number">4</span> * <span class="number">4</span> * <span class="number">256</span>], name=<span class="string">&quot;reshape&quot;</span>)</span><br><span class="line"></span><br><span class="line">    dropf = dropout(drop3_flat, <span class="number">0.5</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># out</span></span><br><span class="line">    <span class="keyword">with</span> tf.name_scope(<span class="string">&quot;out&quot;</span>):</span><br><span class="line">        Wf = weight_variable([<span class="number">4</span>*<span class="number">4</span>*<span class="number">256</span>, <span class="number">10</span>])</span><br><span class="line">        bf = bias_variable([<span class="number">10</span>])</span><br><span class="line">        dense = tf.matmul(dropf, Wf) + bf</span><br></pre></td></tr></table></figure>

<p>Layer1由两个卷积接一个max_pooling完成。第一层卷积在每个3x3的patch中算出64个特征值。权重是一个[3, 3, 3, 64]的张量，前两个维度是卷积核（patch）的大小，接着是输入通道，最后一个是输出通道，输出对应同样大小的偏置向量。第二层卷积在每个3x3的patch中会得到64个特征。后接一个最大池化层，进行图片采样，进入下一个隐含层。</p>
<p>为了构建一个更深的网络结构，本文将几个类似的层堆叠起来，layer2和layer3的结构几乎一样。layer2中每个3x3的patch会得到128个特征，layer3中每个3x3的patch会得到256个特征。</p>
<p>Layer3执行完毕后，图片的大小为(4x4)x256（最后一层输出特征图大小为256），紧接着通过tensorflow的reshape将这个四维张量拉直成一个二维张量（第1维是图片的序列，第二维是所有的图片特征）。然后接一个dropout防止过拟合。<br>本文所定义的CNN结构不包含全连接层（测试过添加一层256节点的全连接层，训练80个循环以后，测试集只能达到72%左右的准确率，效果比不加还要差）。</p>
<p>最后直接跟输出层，输入图片大小为(4x4)x256，输出10个特征图，即图片的十个分类，输出层由欧式径向基函数（RBF，Euclidean Radial Basis Function）单元组成，每个类一个单元，每个单元由4x4x256个输入，输出层的作用函数为线性函数，对隐藏层神经元输出的结果进行线性加权后输出，作为整个神经网络的输出结果。</p>
<h2 id="定义训练方式"><a href="#定义训练方式" class="headerlink" title="定义训练方式"></a>定义训练方式</h2><h3 id="定义模型训练指标"><a href="#定义模型训练指标" class="headerlink" title="定义模型训练指标"></a>定义模型训练指标</h3><p>卷积网络在本质上是一种输入到输出的映射，它能够学习大量的输入与输出之间的映射关系，而不需要任何输入和输出之间的精确的数学表达式，只要用已知的模式对卷积网络加以训练，网络就具有输入输出对之间的映射能力。</p>
<p>卷积网络执行的是监督训练，所以其样本集是由形如：（输入向量，理想输出向量）的向量对构成的。所有这些向量对，都是来源于已经准备好的训练数据集。</p>
<p>定义训练方法代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">out = inference(x)</span><br><span class="line"></span><br><span class="line">    p = tf.nn.softmax(out, name=<span class="string">&quot;outnode&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> tf.name_scope(<span class="string">&quot;loss&quot;</span>):</span><br><span class="line">        cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=out, labels=y_))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> tf.name_scope(<span class="string">&quot;train&quot;</span>):</span><br><span class="line">        train_step = tf.train.AdamOptimizer(<span class="number">1e-4</span>).minimize(cross_entropy)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> tf.name_scope(<span class="string">&quot;accuracy&quot;</span>):</span><br><span class="line">        accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(out, <span class="number">1</span>), tf.argmax(y_, <span class="number">1</span>)), tf.float32))</span><br><span class="line">    tf.summary.scalar(<span class="string">&#x27;loss&#x27;</span>, cross_entropy)</span><br><span class="line">    tf.summary.scalar(<span class="string">&#x27;train_accuracy&#x27;</span>, accuracy)</span><br></pre></td></tr></table></figure>

<p>模型训练分为以下两个阶段：</p>
<p>第一阶段，前向传播阶段：</p>
<ol>
<li>样本集中取一个样本，输入网络</li>
<li>计算相应的实际输出；在此阶段，信息从输入层经过逐级的变换，传送到输出层。</li>
</ol>
<p>这个过程也是网络在完成训练后正常执行时执行的过程。</p>
<p>第二阶段，反向传播阶段（BP）：</p>
<ol>
<li>将每个元组的网络预测与真实的类标号相比较，计算差值</li>
<li>按极小化误差的方法，修改权重和偏置，使得网络预测和实际之间的均方误差减小。</li>
</ol>
<p>即由输出层，经由每个隐藏层，到第一个隐藏层（后向传播）。理论上来说，权重和偏置最终会收敛，学习过程停止。</p>
<p>要完成这两步，首先需要定义一个指标来评估这个模型的好坏，在机器学习中一般定义一个指标表示这个模型是坏的，这个指标成为成本（cost）或损失（loss），然后尽量减小这个指标。本文中使用的成本函数是“交叉熵”（cross-entropy），交叉熵产生与信息论，简单来说，交叉熵是衡量两个概率分布p和q之间的相似性，其定义如下：</p>
<p>$$ H_{y’}(y) &#x3D; -\sum_i{y’_i\log y_i} $$</p>
<p>y是预测的概率分布，y&#96;是实际的分布（即输入的ont-hot vector）。</p>
<p>程序中计算交叉熵：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=out, labels=y_))</span><br></pre></td></tr></table></figure>

<p>softmax_cross_entropy_with_logits实现过程如下：</p>
<ol>
<li>对网络输入的最后一层（out）做一个softmax（所以在网络的输出层没有加softmax）</li>
<li>用tf.log计算上层每个结果的对数，然后把y_的每个元素和tf.log(y_)对应的元素相乘</li>
<li>用tf.reduce_sum计算张量的所有元素的总和</li>
</ol>
<p>最后用tf.reduce_mean计算batch维度（第一维度）下交叉熵（cross-entropy）的平均值，并将这个值作为总损失（loss）。</p>
<p>TensorFlow拥有一张描述各个计算单元的图，也就是说TensorFlow是基于图的，并不是基于数据流的，而且它可以自动使用反向传播算法（BP，backpropagation algorithm），有效确定变量是如何影响需要最小化的那个成本值（cross-entropy），然后通过优化算法不断修改变量来降低成本值。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_step = tf.train.AdamOptimizer(<span class="number">1e-4</span>).minimize(cross_entropy)</span><br></pre></td></tr></table></figure>

<p>TensorFlow中有大量内置的优化算法。本文中使用实现了Adam算法的优化器，Adam 也是基于梯度下降的方法，每次迭代参数的学习步长都有一个确定的范围，不会因为很大的梯度导致很大的学习步长，参数的值比较稳定，AdamOptimizer通过使用动量（参数的移动平均数）来改善传统梯度下降，促进参数的动态调整。然后以1e-4的学习效率最小化交叉熵。</p>
<p>这一步实际上是用来往图上添加一个新操作，其中包括计算梯度，计算每个参数的步长变化，并且计算出新的参数值。整个模型可以反复地运行train_step完成梯度下降来更新权值，不断减少损失。TensorFlow在这里做的是，它在后台给计算的那张图里面增加一系列新的操作单元用于实现反向传播算法和梯度下降算法。然后，返回一个单一的操作。也就是说，它把那些繁琐的操作都进行了封装，直接调用即可。</p>
<h3 id="模型评估"><a href="#模型评估" class="headerlink" title="模型评估"></a>模型评估</h3><p>训练模型之后，需要定量评估模型的性能以及准确率如何，分类算法的模型是基于数值输入预测分类值，实际目标是1和0的序列。这就需要度量预测值和真实值之间的距离。分类算法的损失函数一般不容易评估模型的好坏，所以通常情况下是看准确预测分类结果的百分比。</p>
<p>首先需要找出哪些lable是预测正确的，然后除以总数得到正确率。</p>
<p>实现代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(out, <span class="number">1</span>), tf.argmax(y_, <span class="number">1</span>)), tf.float32))</span><br></pre></td></tr></table></figure>

<p>其中tf.argmax会返回一个张量某个维度中的最大值得索引，如tf.argmax(out,1)表示模型对每个输入的最大概率的分类的分类值，而tf.argmax(y_,1)表示真实分类的分类值。然后用tf.equal来判断预测是否和真实分类一致。到这一步返回的是一个布尔数组，为了计算准确率，通过tf.cast将布尔值转化为浮点数来代表对、错（如1代表对、0代表错），然后通过tf.reduce_mean取平均值。</p>
<h3 id="安卓的输出节点"><a href="#安卓的输出节点" class="headerlink" title="安卓的输出节点"></a>安卓的输出节点</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">p = tf.nn.softmax(out, name=<span class="string">&quot;outnode&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>这里使用了softmax回归（softmax regression）模型，这个模型可以用来给不同的对象分配概率，关于softmax定义如下：</p>
<p>$$ softmax(x)_i &#x3D; \frac {exp(x_i)} {\sum_j{exp(x_j)}} $$</p>
<p>Softmax把输入值当成幂指数求值，然后再正则化这些结果。这个幂运算表示，更大的evidence对应更大的假设模型里面的乘数权重值，反之，更少的evidence意味假设模型里面更小的乘数权重值。如果模型里的权值不能是0或者负数，softmax然后会正则化这些权重值，使它们的总和等于1，以此来构造一个有效的概率分布。</p>
<p>这里把softmax看成一个激励（activation）函数，把定义的线性函数输出转换成需要的格式，也就是关于图片的10个类别。所以，给定一张图片，它对于每个类别的吻合成都可以被softmax函数转换成一个概率值。</p>
<p>将这个概率值作为输出节点，并指明输出节点（通过name指定），供安卓端调用。</p>
<h3 id="状态可视化"><a href="#状态可视化" class="headerlink" title="状态可视化"></a>状态可视化</h3><p>Tensorflow发布包中提供了TensorBoard，用于展示Tensorflow任务在计算过程中的Graph、定量指标图以及附加数据。为了释放tensorboard中所使用的事件文件，所有的即时数据都要在图表构建阶段合并到一个操作（op）中。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tf.summary.scalar(<span class="string">&#x27;loss&#x27;</span>, cross_entropy)</span><br><span class="line">   tf.summary.scalar(<span class="string">&#x27;train_accuracy&#x27;</span>, accuracy)</span><br><span class="line"></span><br><span class="line">   merged_summary_op = tf.summary.merge_all()</span><br></pre></td></tr></table></figure>

<p>创建好会话（Session）后，实例化一个tf.summary.FileWriter，用于写入包含图表和即时数据具体值的事件文件</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">summary_writer = tf.summary.FileWriter(<span class="string">&#x27;./tmp&#x27;</span>, graph=tf.get_default_graph())</span><br></pre></td></tr></table></figure>

<p>每次运行merged_summary_op时，都会往事件文件中写入最新的即时数据，函数的输出会传入事件文件读写器（writer）的add_summary()函数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">_,loss,summary = sess.run([train_step, cross_entropy, merged_summary_op],feed_dict=&#123;x:batch_x,y_:batch_y&#125;)</span><br><span class="line"></span><br><span class="line">summary_writer.add_summary(summary, n*num_batch+i)</span><br></pre></td></tr></table></figure>

<p>事件文件写入完毕后，就训练文件夹打开一个Tensorboard，查看即时数据情况。</p>
<h2 id="训练和保存模型"><a href="#训练和保存模型" class="headerlink" title="训练和保存模型"></a>训练和保存模型</h2><h3 id="环境以及配置"><a href="#环境以及配置" class="headerlink" title="环境以及配置"></a>环境以及配置</h3><p>使用计算机配置：</p>
<blockquote>
<p>处理器：Intel 酷睿i3-6100</p>
<p>GPU：NVIDIA GeForce GTX 1050Ti</p>
<p>内存：16G</p>
</blockquote>
<p>运行环境：</p>
<blockquote>
<p>操作系统：windows 10</p>
<p>Python版本：python3.6</p>
<p>TensorFlow版本：tensorflow-1.7</p>
<p>GPU驱动环境：cuda_9.0，cudnn-7.1</p>
</blockquote>
<h3 id="训练模型"><a href="#训练模型" class="headerlink" title="训练模型"></a>训练模型</h3><p>整个训练过程主要包括训练模型、保存即时数据、保存检查点文件（checkpoint file）、评估模型几个部分。具体代码如下所示：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">load_model</span>(<span class="params">sess, saver,ckpt_path</span>):</span><br><span class="line">    latest_ckpt = tf.train.latest_checkpoint(ckpt_path)</span><br><span class="line">    <span class="built_in">print</span>(latest_ckpt)</span><br><span class="line">    <span class="keyword">if</span> latest_ckpt:</span><br><span class="line">        <span class="built_in">print</span> (<span class="string">&#x27;恢复模型-&#x27;</span>, latest_ckpt)</span><br><span class="line">        saver.restore(sess, latest_ckpt)</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">int</span>(latest_ckpt[latest_ckpt.rindex(<span class="string">&#x27;-&#x27;</span>) + <span class="number">1</span>:])</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span> (<span class="string">&#x27;新建模型&#x27;</span>)</span><br><span class="line">        sess.run(tf.global_variables_initializer())</span><br><span class="line">        <span class="keyword">return</span> -<span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">cnn_train</span>(<span class="params">batch, x_train, y_train, x_test, y_test</span>):</span><br><span class="line"></span><br><span class="line">    num_batch = <span class="built_in">len</span>(x_train) // batch</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line"></span><br><span class="line">        <span class="comment"># load model</span></span><br><span class="line">        sess.run(tf.initialize_all_variables())</span><br><span class="line"></span><br><span class="line">        saver = tf.train.Saver(tf.all_variables())</span><br><span class="line">        last_epoch = load_model(sess, saver, <span class="string">&#x27;save_model/&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        summary_writer = tf.summary.FileWriter(<span class="string">&#x27;./tmp &#x27;</span>, graph=tf.get_default_graph())</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> n <span class="keyword">in</span> <span class="built_in">range</span>(last_epoch + <span class="number">1</span>, <span class="number">1000</span>):</span><br><span class="line">            <span class="comment"># 每次取batch_size张图片</span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_batch):</span><br><span class="line">                batch_x = x_train[i*batch : (i+<span class="number">1</span>)*batch]</span><br><span class="line">                batch_y = y_train[i*batch : (i+<span class="number">1</span>)*batch]</span><br><span class="line">                <span class="comment"># 开始训练数据，同时训练三个变量，返回三个数据</span></span><br><span class="line">                _,loss,summary = sess.run([train_step, cross_entropy, merged_summary_op],</span><br><span class="line">                                           feed_dict=&#123;x:batch_x,y_:batch_y&#125;)</span><br><span class="line">                summary_writer.add_summary(summary, n*num_batch+i)</span><br><span class="line"></span><br><span class="line">                <span class="comment"># 打印损失</span></span><br><span class="line">                <span class="keyword">if</span> (n*num_batch+i) % <span class="number">10</span> == <span class="number">0</span>:</span><br><span class="line">                    <span class="built_in">print</span>(n*num_batch+i, loss)</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> (n*num_batch+i) % <span class="number">50</span> == <span class="number">0</span>:</span><br><span class="line">                    <span class="comment"># 获取测试数据的准确率</span></span><br><span class="line">                    x_test_t = x_test[<span class="number">0</span>: <span class="number">2000</span>]</span><br><span class="line">                    y_test_t = y_test[<span class="number">0</span>: <span class="number">2000</span>]</span><br><span class="line">                    acc = sess.run(accuracy, feed_dict=&#123;x:x_test_t, y_:y_test_t&#125;)</span><br><span class="line">                    <span class="comment"># tf.summary.scalar(&#x27;test_accuracy&#x27;, acc)</span></span><br><span class="line">                    <span class="built_in">print</span>(n*num_batch+i, acc)</span><br><span class="line"></span><br><span class="line">                    <span class="keyword">if</span> acc &gt; <span class="number">0.77</span>:</span><br><span class="line">                        constant_graph = graph_util.convert_variables_to_constants(sess, sess.graph_def, [<span class="string">&quot;outnode&quot;</span>])</span><br><span class="line">                        <span class="keyword">with</span> tf.gfile.FastGFile(<span class="string">&quot;android_model/model-&quot;</span>+<span class="built_in">str</span>(acc)+<span class="string">&quot;.pb&quot;</span>, mode=<span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">                            f.write(constant_graph.SerializeToString())</span><br><span class="line">            saver.save(sess, <span class="string">&#x27;save_model /cifar.model&#x27;</span>, global_step=n)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    cifar10_dir = <span class="string">&#x27;data/cifar-10-batches-py/&#x27;</span></span><br><span class="line">    X_train, y_train, X_test, y_test = input_data.load_CIFAR10(cifar10_dir)</span><br><span class="line">    batch_size = <span class="number">128</span></span><br><span class="line"></span><br><span class="line">    cnn_train(batch_size, X_train, y_train, X_test, y_test)</span><br></pre></td></tr></table></figure>

<p>Tensorflow结构以C API为界限，将整个系统分为“前端”和“后端”两个子系统，前端系统提供编程模型，负责构造计算图。后端用C&#x2F;C++语言编写，运算速度比较快，因此后端提供运行时环境，负责执行计算图。前端通过Session连接后端，所以tensorflow构建的计算图必须通过session会话才能执行。</p>
<p>构造图的阶段完成后，才能启动图。启动图的第一步是创建一个Session对象, 如果无任何创建参数, 会话构造器将启动默认图。会话会管理TensorFlow程序运行时的所有资源。当所有计算完成之后需要关闭会话来帮助系统回收资源，否则就可能出现资源泄露的问题，本文中使用Python上下文管理器来使用会话，当上下文退出时，关闭和资源释放也会自动完成。</p>
<p>在训练过程中，传入的整个图像和标签数据集会被切片，以符合每个操作所设置的batch值，占位符操作将填补以符合这个值，然后使用feed_dict参数，将数据传入会话函数（session）。</p>
<p>模型的训练过程描述如下：</p>
<ol>
<li>取得训练集和验证集，将所有数据输入到训练模型函数中。</li>
<li>选定训练组，本文从样本集中分别随机地寻求128个样本作为一个训练组(batch)。</li>
<li>检测是否有检查点文件（checkpoint file），如果有，直接从文件中恢复上次保存的模型，继续训练；如果没有，新建模型，从头开始训练，并初始化所有参数。</li>
<li>取一个训练组加入到网络，并给出它的目标向量（真实值）。</li>
<li>计算损失（loss）和准确率（accuracy），输出到操作（op）中，并通过优化器来减小损失，调整各层权重和偏置。</li>
<li>每经过N个batch后，用验证集评估模型准确率，判断指标是否满足精度要求，如果满足要求，则将模型保存为安卓端可用的模型（.pb为后缀的模型，保存了整张图和每层的权重和偏置），如果不满足，则跳过不保存</li>
<li>训练集每经过一次迭代，就保存模型，向训练文件夹中写入包含了所有课训练变量的值的检查点文件（checkpoint file），以便于中断训练后，可以直接从上次训练的部分恢复继续训练，不需要再进行初始化。</li>
<li>迭代结束或者键盘中断，则结束训练。</li>
</ol>
<p>在循环的每个步骤中，程序都会抓取训练数据中的128个批处理数据点（也就是一个batch），然后用这些数据点作为参数替换之前的占位符来运行train_step。</p>
<p>如此反复多次，直到最终误差收敛。</p>
<p>本文使用随机训练（stochastic training）的方法，每次使用其中一小部分的随机数据来进行训练，更确切地说是随机梯度下降训练。在理想的情况下，所有的数据都来进行每一步的训练，这能得到更好的训练结果，但是这显然也需要很大的计算开销。所以，每一次训练的时候，使用不同的数据子集，这样既可以减少计算开销，又可以最大化地学习到数据集的总特性。</p>
<p>在一块GPU上运行了大约81000个batch，也就是210左右次迭代，大约用了一个半小时，该模型使用验证集评估，最高达到80%的精度。</p>
<h3 id="保存模型"><a href="#保存模型" class="headerlink" title="保存模型"></a>保存模型</h3><p>在官方api中，提供了两种不同的模型保存方法。</p>
<p>一种是使用tf.train.Saver()保存，这种方式只保存了网络中的各层参数值，并不保存模型结构。这种方式有几个缺点，首先这种模型文件是依赖tensorflow的，只能在tensorflow框架下使用，其次在恢复模型参数之前，还需要再定义一遍网络结构，然后才能恢复到网络中。</p>
<p>另外一种是基于Protocol Buffers的序列化协议，将网络中各层参数值和网络模型结构通过预定好的格式进行持久化保存，也是谷歌推荐的保存模型的方式，它可以独立运行，封闭的序列化格式，任何语言都可以解析它。另外的好处是保存为pb文件的时候，模型的变量都会变成固定的，导致模型大小会大大减小，适合手机端运行。</p>
<p>保存模型具体代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">constant_graph = graph_util.convert_variables_to_constants(sess, sess.graph_def, [<span class="string">&quot;outnode&quot;</span>])</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.gfile.FastGFile(<span class="string">&quot;android_model/model-&quot;</span>+<span class="built_in">str</span>(acc)+<span class="string">&quot;.pb&quot;</span>, mode=<span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.write(constant_graph.SerializeToString())</span><br><span class="line">        saver.save(sess, <span class="string">&#x27;save_model /cifar.model&#x27;</span>, global_step=n)</span><br></pre></td></tr></table></figure>
<p>这样就将模型保存为了.pb后缀的文件，这样的模型文件会在之后移植到安卓端的时候使用。</p>
<h3 id="训练结果分析"><a href="#训练结果分析" class="headerlink" title="训练结果分析"></a>训练结果分析</h3><p>本文中使用的模型总参量为120万左右，这还是简化后的VGG16模型，在一块1050ti的GPU上训练了一个半小时左右，经过210次左右迭代。</p>
<p>在经过20000个batch后损失的变化就相对来说比较小了，损失没有上升趋势，说明没有出现过拟合情况。而且在运行时间不长的情况下，说明参数收敛的比较快。在1小时33分钟左右，经过约80000个batch后，损失值达到4.27e-3。此时对于训练集的准确率达到了99.22%，相对来说，应该算是比较好的结果。</p>
<p>对于训练集，在经过约30000个batch以后，准确率基本维持在98%以上，在到达80000个batch以后，一直稳定在99%以上。也就是说对于当前这个数据集来说，模型继续学习下去得到的收益并不大。可以通过引入新的数据集或者调节各个图像的对比度等等，增加样本多样性，以此增加模型精度。</p>
<p>对于测试集的准确率，最高达到了80%，而官方提供模型准确率是86%。</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">Ansore</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://blog.ansore.top/posts/4c3e71da.html">https://blog.ansore.top/posts/4c3e71da.html</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://blog.ansore.top" target="_blank">Ansore</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/cnn/">cnn</a><a class="post-meta__tags" href="/tags/tensorflow/">tensorflow</a><a class="post-meta__tags" href="/tags/cifar/">cifar</a></div><div class="post_share"><div class="social-share" data-image="https://img.ansore.de/2022/04/28/626969f586f24.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/posts/ef296a07.html"><img class="prev-cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.ansore.de/2022/04/28/6269696188c94.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">决策树算法</div></div></a></div><div class="next-post pull-right"><a href="/posts/fb40efc5.html"><img class="next-cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.ansore.de/2022/04/27/62692f1609241.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">拓扑排序</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/posts/7931261f.html" title="图片与TFRecord的相互转化"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.ansore.de/2022/04/28/626969f586f24.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2019-03-01</div><div class="title">图片与TFRecord的相互转化</div></div></a></div><div><a href="/posts/9658a59d.html" title="用tf.data读取TFRecord"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.ansore.de/2022/04/28/626969f586f24.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2019-03-19</div><div class="title">用tf.data读取TFRecord</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/images/logo.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Ansore</div><div class="author-info__description">纵然时光倒流<br>我还是想象不出一切最开始的模样</div></div><div class="card-info-data is-center"><div class="card-info-data-item"><a href="/archives/"><div class="headline">文章</div><div class="length-num">176</div></a></div><div class="card-info-data-item"><a href="/tags/"><div class="headline">标签</div><div class="length-num">52</div></a></div><div class="card-info-data-item"><a href="/categories/"><div class="headline">分类</div><div class="length-num">21</div></a></div></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/Ansore"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/Ansore" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:aansore@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">一枕邯郸，一生荒唐</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E5%AF%BC%E5%85%A5%E5%92%8C%E9%A2%84%E5%A4%84%E7%90%86"><span class="toc-number">1.</span> <span class="toc-text">数据导入和预处理</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%9B%E5%BB%BA%E6%A8%A1%E5%9E%8B"><span class="toc-number">2.</span> <span class="toc-text">创建模型</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9A%E4%B9%89%E5%8D%A0%E4%BD%8D%E7%AC%A6"><span class="toc-number">2.1.</span> <span class="toc-text">定义占位符</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9D%83%E9%87%8D%E5%92%8C%E5%81%8F%E7%BD%AE%E5%88%9D%E5%A7%8B%E5%8C%96"><span class="toc-number">2.2.</span> <span class="toc-text">权重和偏置初始化</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8D%B7%E7%A7%AF%E3%80%81%E6%B1%A0%E5%8C%96%E5%92%8Cdropout"><span class="toc-number">2.3.</span> <span class="toc-text">卷积、池化和dropout</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9A%E4%B9%89%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84"><span class="toc-number">2.4.</span> <span class="toc-text">定义网络结构</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%9A%E4%B9%89%E8%AE%AD%E7%BB%83%E6%96%B9%E5%BC%8F"><span class="toc-number">3.</span> <span class="toc-text">定义训练方式</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9A%E4%B9%89%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E6%8C%87%E6%A0%87"><span class="toc-number">3.1.</span> <span class="toc-text">定义模型训练指标</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0"><span class="toc-number">3.2.</span> <span class="toc-text">模型评估</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%89%E5%8D%93%E7%9A%84%E8%BE%93%E5%87%BA%E8%8A%82%E7%82%B9"><span class="toc-number">3.3.</span> <span class="toc-text">安卓的输出节点</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%8A%B6%E6%80%81%E5%8F%AF%E8%A7%86%E5%8C%96"><span class="toc-number">3.4.</span> <span class="toc-text">状态可视化</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83%E5%92%8C%E4%BF%9D%E5%AD%98%E6%A8%A1%E5%9E%8B"><span class="toc-number">4.</span> <span class="toc-text">训练和保存模型</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%8E%AF%E5%A2%83%E4%BB%A5%E5%8F%8A%E9%85%8D%E7%BD%AE"><span class="toc-number">4.1.</span> <span class="toc-text">环境以及配置</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B"><span class="toc-number">4.2.</span> <span class="toc-text">训练模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BF%9D%E5%AD%98%E6%A8%A1%E5%9E%8B"><span class="toc-number">4.3.</span> <span class="toc-text">保存模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83%E7%BB%93%E6%9E%9C%E5%88%86%E6%9E%90"><span class="toc-number">4.4.</span> <span class="toc-text">训练结果分析</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/posts/e060854e.html" title="Archlinux安装btrfs文件系统"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.ansore.de/2022/04/25/6266bea760d6c.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Archlinux安装btrfs文件系统"/></a><div class="content"><a class="title" href="/posts/e060854e.html" title="Archlinux安装btrfs文件系统">Archlinux安装btrfs文件系统</a><time datetime="2023-12-03T14:42:08.000Z" title="发表于 2023-12-03 22:42:08">2023-12-03</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/18aaf2d9.html" title="KVM与实体机共享目录"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.ansore.de/2022/04/25/6266bea760d6c.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="KVM与实体机共享目录"/></a><div class="content"><a class="title" href="/posts/18aaf2d9.html" title="KVM与实体机共享目录">KVM与实体机共享目录</a><time datetime="2023-05-06T14:43:03.000Z" title="发表于 2023-05-06 22:43:03">2023-05-06</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/4cb3e1a1.html" title="Linux中找到并删除重复文件的工具"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.ansore.de/2022/04/25/6266bea760d6c.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Linux中找到并删除重复文件的工具"/></a><div class="content"><a class="title" href="/posts/4cb3e1a1.html" title="Linux中找到并删除重复文件的工具">Linux中找到并删除重复文件的工具</a><time datetime="2023-02-11T12:44:11.000Z" title="发表于 2023-02-11 20:44:11">2023-02-11</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/28e97253.html" title="QEMU搭建ARM32环境"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.ansore.de/2022/04/25/6266bea760d6c.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="QEMU搭建ARM32环境"/></a><div class="content"><a class="title" href="/posts/28e97253.html" title="QEMU搭建ARM32环境">QEMU搭建ARM32环境</a><time datetime="2023-01-03T14:40:02.000Z" title="发表于 2023-01-03 22:40:02">2023-01-03</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/330229db.html" title="64位操作系统-地址空间"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.ansore.de/2022/09/11/f01cf15d850f0ce8f2c97c93a206411c8d3bf927.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="64位操作系统-地址空间"/></a><div class="content"><a class="title" href="/posts/330229db.html" title="64位操作系统-地址空间">64位操作系统-地址空间</a><time datetime="2022-09-18T02:31:20.000Z" title="发表于 2022-09-18 10:31:20">2022-09-18</time></div></div></div></div></div></div></main><footer id="footer" style="background-image: url('https://img.ansore.de/2022/04/28/626969f586f24.jpg')"><div id="footer-wrap"><div class="copyright">&copy;2016 - 2024 By Ansore</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">繁</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">本地搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script>function panguFn () {
  if (typeof pangu === 'object') pangu.autoSpacingPage()
  else {
    getScript('https://cdn.jsdelivr.net/npm/pangu/dist/browser/pangu.min.js')
      .then(() => {
        pangu.autoSpacingPage()
      })
  }
}

function panguInit () {
  if (false){
    GLOBAL_CONFIG_SITE.isPost && panguFn()
  } else {
    panguFn()
  }
}

document.addEventListener('DOMContentLoaded', panguInit)</script><script src="/js/search/local-search.js"></script><script>var preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',preloader.endLoading())</script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    chtml: {
      scale: 1.2
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        insertScript: [200, () => {
          document.querySelectorAll('mjx-container:not\([display]\)').forEach(node => {
            const target = node.parentNode
            if (target.nodeName.toLowerCase() === 'li') {
              target.parentNode.classList.add('has-jax')
            } else {
              target.classList.add('has-jax')
            }
          });
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typeset()
}</script><script>(() => {
  const $mermaidWrap = document.querySelectorAll('#article-container .mermaid-wrap')
  if ($mermaidWrap.length) {
    window.runMermaid = () => {
      window.loadMermaid = true
      const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark' : 'default'

      Array.from($mermaidWrap).forEach((item, index) => {
        const mermaidSrc = item.firstElementChild
        const mermaidThemeConfig = '%%{init:{ \'theme\':\'' + theme + '\'}}%%\n'
        const mermaidID = 'mermaid-' + index
        const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent
        mermaid.mermaidAPI.render(mermaidID, mermaidDefinition, (svgCode) => {
          mermaidSrc.insertAdjacentHTML('afterend', svgCode)
        })
      })
    }

    const loadMermaid = () => {
      window.loadMermaid ? runMermaid() : getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(runMermaid)
    }

    window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
  }
})()</script></div><script defer="defer" id="fluttering_ribbon" mobile="true" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-fluttering-ribbon.min.js"></script><script id="click-heart" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/click-heart.min.js" async="async" mobile="true"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>